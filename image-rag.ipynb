{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPModelHandler:\n",
    "    def __init__(self, model_name=\"openai/clip-vit-base-patch32\"):\n",
    "        self.model = CLIPModel.from_pretrained(model_name)\n",
    "        self.processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "    def get_image_embedding(self, image):\n",
    "        # Process image\n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            embeddings = self.model.get_image_features(**inputs)\n",
    "        return embeddings.cpu().numpy()\n",
    "\n",
    "    def get_text_embedding(self, text):\n",
    "        # Process text\n",
    "        inputs = self.processor(text=[text], return_tensors=\"pt\", padding=True)\n",
    "        with torch.no_grad():\n",
    "            embeddings = self.model.get_text_features(**inputs)\n",
    "        return embeddings.cpu().numpy()\n",
    "\n",
    "class ImageDatabase:\n",
    "    def __init__(self, db_file=\"image_db.json\"):\n",
    "        self.db_file = db_file\n",
    "        self.image_data = self.load_db()\n",
    "\n",
    "    def load_db(self):\n",
    "        if os.path.exists(self.db_file):\n",
    "            with open(self.db_file, \"r\") as file:\n",
    "                return json.load(file)\n",
    "        else:\n",
    "            return {}\n",
    "\n",
    "    def save_db(self):\n",
    "        with open(self.db_file, \"w\") as file:\n",
    "            json.dump(self.image_data, file)\n",
    "\n",
    "    def add_image(self, image_path, embedding):\n",
    "        self.image_data[image_path] = {\n",
    "            \"embedding\": embedding.tolist(),\n",
    "            \"image_path\": image_path\n",
    "        }\n",
    "\n",
    "    def get_all_embeddings(self):\n",
    "        return np.array([data[\"embedding\"] for data in self.image_data.values()])\n",
    "\n",
    "    def get_image_paths(self):\n",
    "        return list(self.image_data.keys())\n",
    "\n",
    "class RAGPipeline:\n",
    "    def __init__(self, model_handler, image_db):\n",
    "        self.model_handler = model_handler\n",
    "        self.image_db = image_db\n",
    "\n",
    "    def store_image_embeddings(self, image_dir):\n",
    "        # Process all images in the directory\n",
    "        for image_name in tqdm(os.listdir(image_dir)):\n",
    "            if image_name.endswith(\".webp\"):\n",
    "                if image_name in self.image_db.image_data:\n",
    "                    continue\n",
    "                image_path = os.path.join(image_dir, image_name)\n",
    "                image = Image.open(image_path)\n",
    "                embedding = self.model_handler.get_image_embedding(image)\n",
    "                self.image_db.add_image(image_path, embedding)\n",
    "        self.image_db.save_db()\n",
    "\n",
    "    def retrieve_top_k(self, text_description,top_k=5):\n",
    "        # Get text embedding\n",
    "        text_embedding = np.array(self.model_handler.get_text_embedding(text_description))[0]\n",
    "\n",
    "        # Get all image embeddings\n",
    "        image_embeddings = np.array(self.image_db.get_all_embeddings())[:,0]\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        similarities = cosine_similarity([text_embedding], image_embeddings).flatten()\n",
    "\n",
    "        # Get top-k indices\n",
    "        top_k_indices = similarities.argsort()[-top_k:][::-1]\n",
    "\n",
    "        # Retrieve top-k image paths\n",
    "        image_paths = np.array(self.image_db.get_image_paths())[top_k_indices]\n",
    "\n",
    "        return image_paths, similarities[top_k_indices]\n",
    "    \n",
    "    def retrieve_top_k_with_image(self, image_path,top_k=5):\n",
    "        # Get image embedding\n",
    "        image = Image.open(image_path)\n",
    "        image_embedding = self.model_handler.get_image_embedding(image)\n",
    "\n",
    "        # Get all image embeddings\n",
    "        image_embeddings = np.array(self.image_db.get_all_embeddings())[:,0]\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        similarities = cosine_similarity(image_embedding, image_embeddings).flatten()\n",
    "\n",
    "        # Get top-k indices\n",
    "        top_k_indices = similarities.argsort()[-top_k:][::-1]\n",
    "\n",
    "        # Retrieve top-k image paths\n",
    "        image_paths = np.array(self.image_db.get_image_paths())[top_k_indices]\n",
    "\n",
    "        return image_paths, similarities[top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_handler = CLIPModelHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9290306]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(\n",
    "    model_handler.get_text_embedding(\"Karim KARIM KaRiM\"),\n",
    "    model_handler.get_text_embedding(\"Karim is \")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teach_with_image_caption(image , caption):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_db = ImageDatabase(\"image_db.json\")\n",
    "rag_pipeline = RAGPipeline(model_handler, image_db, top_k=20)\n",
    "# rag_pipeline.store_image_embeddings(\"./WhatsApp-Stickers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n",
      "(8126, 512)\n",
      "Image: ./WhatsApp-Stickers/STK-20210408-WA0050.webp, Similarity: 0.31752158451610424\n",
      "Image: ./WhatsApp-Stickers/STK-20240709-WA0014.webp, Similarity: 0.30731167439716567\n",
      "Image: ./WhatsApp-Stickers/STK-20240419-WA0013.webp, Similarity: 0.27728643630470473\n",
      "Image: ./WhatsApp-Stickers/STK-20240629-WA0004.webp, Similarity: 0.27726663677550034\n",
      "Image: ./WhatsApp-Stickers/STK-20230911-WA0002.webp, Similarity: 0.2692796310062471\n",
      "Image: ./WhatsApp-Stickers/STK-20221005-WA0002.webp, Similarity: 0.26872216333119603\n",
      "Image: ./WhatsApp-Stickers/STK-20201123-WA0062.webp, Similarity: 0.2684034479995195\n",
      "Image: ./WhatsApp-Stickers/STK-20210702-WA0004.webp, Similarity: 0.2674686101165349\n",
      "Image: ./WhatsApp-Stickers/STK-20210113-WA0012.webp, Similarity: 0.2663539763018652\n",
      "Image: ./WhatsApp-Stickers/STK-20220425-WA0022.webp, Similarity: 0.26552057978475896\n",
      "Image: ./WhatsApp-Stickers/STK-20210522-WA0001.webp, Similarity: 0.26482932589941727\n",
      "Image: ./WhatsApp-Stickers/STK-20211214-WA0027.webp, Similarity: 0.26395751159388336\n",
      "Image: ./WhatsApp-Stickers/STK-20220108-WA0003.webp, Similarity: 0.2639031435688015\n",
      "Image: ./WhatsApp-Stickers/STK-20230215-WA0005.webp, Similarity: 0.26255277664070176\n",
      "Image: ./WhatsApp-Stickers/STK-20220207-WA0015.webp, Similarity: 0.2617061080842464\n",
      "Image: ./WhatsApp-Stickers/STK-20210207-WA0009.webp, Similarity: 0.26115677012513716\n",
      "Image: ./WhatsApp-Stickers/STK-20201211-WA0011.webp, Similarity: 0.25996702005019895\n",
      "Image: ./WhatsApp-Stickers/STK-20210120-WA0041.webp, Similarity: 0.25995628275462435\n",
      "Image: ./WhatsApp-Stickers/STK-20201203-WA0003.webp, Similarity: 0.2596997095098975\n",
      "Image: ./WhatsApp-Stickers/STK-20220420-WA0012.webp, Similarity: 0.25959934833771897\n"
     ]
    }
   ],
   "source": [
    "# Retrieve top-k images for a given text description\n",
    "text_description = \"Mark Zuckerberg good job team\"\n",
    "top_k_images, top_k_similarities = rag_pipeline.retrieve_top_k(text_description)\n",
    "\n",
    "for img_path, similarity in zip(top_k_images, top_k_similarities):\n",
    "    print(f\"Image: {img_path}, Similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: ./WhatsApp-Stickers/STK-20240922-WA0058.webp, Similarity: 1.0000000000000013\n",
      "Image: ./WhatsApp-Stickers/STK-20210408-WA0002.webp, Similarity: 0.991802594534197\n",
      "Image: ./WhatsApp-Stickers/STK-20210411-WA0007.webp, Similarity: 0.7937019988029289\n",
      "Image: ./WhatsApp-Stickers/STK-20240912-WA0037.webp, Similarity: 0.7806971058890797\n",
      "Image: ./WhatsApp-Stickers/STK-20210424-WA0054.webp, Similarity: 0.7701733408645601\n",
      "Image: ./WhatsApp-Stickers/STK-20211118-WA0009.webp, Similarity: 0.7595438039673797\n",
      "Image: ./WhatsApp-Stickers/STK-20210415-WA0013.webp, Similarity: 0.7544395148228715\n",
      "Image: ./WhatsApp-Stickers/STK-20210408-WA0028.webp, Similarity: 0.7524808492695164\n",
      "Image: ./WhatsApp-Stickers/STK-20210411-WA0005.webp, Similarity: 0.7489389823805476\n",
      "Image: ./WhatsApp-Stickers/STK-20210411-WA0006.webp, Similarity: 0.7458556883054313\n",
      "Image: ./WhatsApp-Stickers/STK-20210112-WA0035.webp, Similarity: 0.7355798537040582\n",
      "Image: ./WhatsApp-Stickers/STK-20210415-WA0017.webp, Similarity: 0.7350884189000522\n",
      "Image: ./WhatsApp-Stickers/STK-20210408-WA0003.webp, Similarity: 0.7345755959422329\n",
      "Image: ./WhatsApp-Stickers/STK-20240420-WA0041.webp, Similarity: 0.7302619693956093\n",
      "Image: ./WhatsApp-Stickers/STK-20210408-WA0041.webp, Similarity: 0.7293054914553462\n",
      "Image: ./WhatsApp-Stickers/STK-20210408-WA0021.webp, Similarity: 0.7292824377244485\n",
      "Image: ./WhatsApp-Stickers/STK-20210424-WA0120.webp, Similarity: 0.7292429201219799\n",
      "Image: ./WhatsApp-Stickers/STK-20240603-WA0000.webp, Similarity: 0.7291802830236446\n",
      "Image: ./WhatsApp-Stickers/STK-20210424-WA0051.webp, Similarity: 0.7278044482021753\n",
      "Image: ./WhatsApp-Stickers/STK-20210408-WA0017.webp, Similarity: 0.7271071560751572\n"
     ]
    }
   ],
   "source": [
    "# Target image path\n",
    "image_path = \"./WhatsApp-Stickers/STK-20240922-WA0058.webp\"\n",
    "top_k_images, top_k_similarities = rag_pipeline.retrieve_top_k_with_image(image_path)\n",
    "\n",
    "for img_path, similarity in zip(top_k_images, top_k_similarities):\n",
    "    print(f\"Image: {img_path}, Similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
