{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import bfloat16\n",
    "import transformers\n",
    "import os\n",
    "import transformers\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: ./private/cache/llam32-1/: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# %rm -r './private/cache/llam32-1/'\n",
    "# cache_dir='./private/cache/llama/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# print(\"### Hugging face login\")\n",
    "# os.environ[\"HF_TOKEN\"] = getpass.getpass(\"Enter your Hugging Face API key: \")\n",
    "# login(os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = './private/cache/llama32-1i/'\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\", cache_dir=cache_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "model_path = \"./private/cache/llama32-1i/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model_path, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    # device_map=\"auto\",\n",
    "    # cache_dir=cache_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [\n",
    "    \"The patient, a 67-year-old male with a BMI of 32 kg/m², presents with a 12-year history of HTN, T2DM (HbA1c 8.9%), and a recent NSTEMI managed with PCI to the LAD, complicated by LVEF of 38%. Baseline labs show elevated CRP (12 mg/L), BUN (24 mg/dL), and serum Cr of 1.5 mg/dL (eGFR of 52 mL/min/1.73m²). EKG reveals a QRS duration of 132 ms with LBBB morphology, while a TTE indicates moderate MR and dilated LV with an end-diastolic diameter of 6.5 cm. PFTs confirm moderate obstructive lung disease with FEV1 at 60% predicted and an FEV1/FVC ratio of 0.58, with DLCO reduced to 65% of predicted, suggestive of concurrent emphysema secondary to a 45-pack-year smoking history. The patient is currently on dual antiplatelet therapy (DAPT) with ASA 81 mg and clopidogrel 75 mg, high-intensity atorvastatin (80 mg), and ACEi titrated to target dose; however, BP remains uncontrolled (average 158/92 mmHg) despite the addition of HCTZ 25 mg and amlodipine 10 mg daily.\",\n",
    "    \"The 55-year-old female with a BMI of 28 kg/m² reports progressive dyspnea and orthopnea. BNP levels are elevated at 520 pg/mL, with a serum Na+ of 133 mEq/L and K+ of 5.1 mEq/L. Echocardiogram reveals an LVEF of 25%, along with grade III diastolic dysfunction and severe MR. Coronary angiography identifies significant stenosis in the RCA, requiring DES placement. Pulmonary function tests (PFTs) show a TLC of 80% predicted, with a DLCO at 55%, consistent with restrictive physiology.\",\n",
    "]\n",
    "\n",
    "contexts_text = \"\\n\\n\".join(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an AI assistant helping users with their questions. You are given some relevant contexts from which you have to answer.\"},\n",
    "    {\"role\": \"system\", \"content\": \"Here are some relevant contexts:\\n\\n\" + contexts_text},\n",
    "    {\"role\": \"user\", \"content\": \"Query: What is the BNP level of the patient?\"},\n",
    "]\n",
    "        \n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BNP (Brain Natriuretic Peptide) level of the patient is elevated at 520 pg/mL.\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0][\"generated_text\"][-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
