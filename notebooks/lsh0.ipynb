{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from itertools import combinations\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"flying fish flew by the space station\",\n",
    "    \"we will not allow you to bring your pet armadillo along\",\n",
    "    \"he figured a few sticks of dynamite were easier than a fishing pole to catch fish\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shingling And One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shingle_document(doc, k=2):\n",
    "    shingles = set()\n",
    "    for i in range(len(doc) - k + 1):\n",
    "        shingles.add(doc[i:i+k])\n",
    "    return shingles\n",
    "\n",
    "def shingle_documents(docs, k=2):\n",
    "    return [shingle_document(d, k) for d in docs]\n",
    "\n",
    "def create_vocab(shingls_list):\n",
    "    vocab = shingls_list[0]\n",
    "    for s in shingls_list[1:]:\n",
    "        vocab = vocab.union(s)\n",
    "    return list(vocab)\n",
    "\n",
    "def create_1hot_enconding(vocab, shingles):\n",
    "    return [1 if v in shingles else 0 for v in vocab]\n",
    "\n",
    "def create_1hot_encondings(vocab, shingles_list):\n",
    "    return [create_1hot_enconding(vocab, s) for s in shingles_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shingled_docs = shingle_documents(docs)\n",
    "vocab = create_vocab(shingled_docs)\n",
    "onehot_docs = create_1hot_encondings(vocab, shingled_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(onehot_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinHashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hash_func(size: int):\n",
    "    # function for creating the hash vector/function\n",
    "    hash_ex = list(range(1, len(vocab)+1))\n",
    "    shuffle(hash_ex)\n",
    "    return hash_ex\n",
    "\n",
    "def build_minhash_func(vocab_size: int, nbits: int):\n",
    "    # function for building multiple minhash vectors\n",
    "    hashes = []\n",
    "    for _ in range(nbits):\n",
    "        hashes.append(create_hash_func(vocab_size))\n",
    "    return hashes\n",
    "\n",
    "def create_hash(one_hot_vector: list,minhash_func: list):\n",
    "    # use this function for creating our signatures (eg the matching)\n",
    "    signature = []\n",
    "    for func in minhash_func:\n",
    "        for i in range(1, len(vocab)+1):\n",
    "            idx = func.index(i)\n",
    "            signature_val = one_hot_vector[idx]\n",
    "            if signature_val == 1:\n",
    "                signature.append(idx)\n",
    "                break\n",
    "    return signature\n",
    "\n",
    "def create_signatures(onehot_docs: list, minhash_func: list):\n",
    "    # create the signatures for all the documents\n",
    "    return [create_hash(doc, minhash_func) for doc in onehot_docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create 20 minhash vectors\n",
    "minhash_func = build_minhash_func(len(vocab), 24)\n",
    "\n",
    "# we create the signatures for all the documents\n",
    "signatures = create_signatures(onehot_docs, minhash_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flying fish flew by the space ... , [44, 43, 70, 93, 44, 98, 27, 43, 71, 93, 35, 44, 20, 30, 21, 99, 21, 87, 20, 27, 71, 21, 87, 87]\n",
      "we will not allow you to bring... , [88, 94, 31, 45, 24, 60, 27, 3, 41, 40, 35, 14, 39, 62, 59, 18, 21, 28, 46, 27, 85, 21, 33, 34]\n",
      "he figured a few sticks of dyn... , [2, 94, 70, 34, 64, 87, 27, 43, 54, 10, 36, 47, 20, 62, 38, 2, 21, 87, 79, 27, 48, 21, 53, 87]\n"
     ]
    }
   ],
   "source": [
    "for doc, sig in zip(docs, signatures):\n",
    "    print(f\"{doc[:30]}... , {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of MinHashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacard_similarity(sig1, sig2):\n",
    "    # calculate the jacard similarity\n",
    "    return len(set(sig1).intersection(sig2)) / len(set(sig1).union(sig2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity(raw) between [0] and [2] is 0.7272727272727273\n",
      "Similarity(1h) between [0] and [2] is 1.0\n",
      "Similarity(minhash) between [0] and [2] is 0.23076923076923078\n"
     ]
    }
   ],
   "source": [
    "ind1 , ind2 = 0, 2\n",
    "print(f\"Similarity(raw) between {[ind1]} and {[ind2]} is {jacard_similarity(docs[ind1], docs[ind2])}\")\n",
    "print(f\"Similarity(1h) between {[ind1]} and {[ind2]} is {jacard_similarity(onehot_docs[ind1], onehot_docs[ind2])}\")\n",
    "print(f\"Similarity(minhash) between {[ind1]} and {[ind2]} is {jacard_similarity(signatures[ind1], signatures[ind2])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locality Sensitive Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_band(signature, b: int):\n",
    "    assert len(signature) % b == 0\n",
    "    r = len(signature) // b\n",
    "    subvecs = [signature[i:i+r] for i in range(0, len(signature), r)]\n",
    "    return subvecs\n",
    "\n",
    "def create_bands(signatures, b: int):\n",
    "    return [create_band(sig, b) for sig in signatures]\n",
    "\n",
    "def is_candidate_match(band1, band2):\n",
    "    for b1, b2 in zip(band1, band2):\n",
    "        if b1 == b2:\n",
    "            print(f\"Found a candidate match: {b1} == {b2}\")\n",
    "            return True\n",
    "    return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = create_bands(signatures, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44, 43, 70, 93], [44, 98, 27, 43], [71, 93, 35, 44], [20, 30, 21, 99], [21, 87, 20, 27], [71, 21, 87, 87]]\n",
      "[[88, 94, 31, 45], [24, 60, 27, 3], [41, 40, 35, 14], [39, 62, 59, 18], [21, 28, 46, 27], [85, 21, 33, 34]]\n",
      "[[2, 94, 70, 34], [64, 87, 27, 43], [54, 10, 36, 47], [20, 62, 38, 2], [21, 87, 79, 27], [48, 21, 53, 87]]\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(bands[0])\n",
    "print(bands[1])\n",
    "print(bands[2])\n",
    "\n",
    "print(is_candidate_match(bands[0], bands[1]))\n",
    "print(is_candidate_match(bands[0], bands[2]))\n",
    "print(is_candidate_match(bands[1], bands[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    def __init__(self, b):\n",
    "        self.b = b\n",
    "        self.buckets = []\n",
    "        self.counter = 0\n",
    "        for i in range(b):\n",
    "            self.buckets.append({})\n",
    "\n",
    "    def make_subvecs(self, signature):\n",
    "        l = len(signature)\n",
    "        assert l % self.b == 0\n",
    "        r = int(l / self.b)\n",
    "        # break signature into subvectors\n",
    "        subvecs = []\n",
    "        for i in range(0, l, r):\n",
    "            subvecs.append(signature[i:i+r])\n",
    "        return np.stack(subvecs)\n",
    "    \n",
    "    def add_hash(self, signature):\n",
    "        subvecs = self.make_subvecs(signature).astype(str)\n",
    "        for i, subvec in enumerate(subvecs):\n",
    "            subvec = ','.join(subvec)\n",
    "            if subvec not in self.buckets[i].keys():\n",
    "                self.buckets[i][subvec] = []\n",
    "            self.buckets[i][subvec].append(self.counter)\n",
    "        self.counter += 1\n",
    "\n",
    "    def add_hashes(self, signatures):\n",
    "        for sig in signatures:\n",
    "            self.add_hash(sig)\n",
    "\n",
    "    def check_candidates(self):\n",
    "        candidates = []\n",
    "        for bucket_band in self.buckets:\n",
    "            keys = bucket_band.keys()\n",
    "            for bucket in keys:\n",
    "                hits = bucket_band[bucket]\n",
    "                if len(hits) > 1:\n",
    "                    candidates.extend(combinations(hits, 2))\n",
    "        return set(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh = LSH(b=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh.add_hashes(signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(lsh.buckets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'27,43': [0, 2], '27,3': [1]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh.buckets[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
